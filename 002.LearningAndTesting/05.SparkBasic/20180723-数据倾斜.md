                                                     spark企业数据倾斜的全套解决方案(数据！您好)
1>过滤少数导致倾斜的key(对业务,计算结果影响不大的情况下使用)
     在业务理解和需求可以进行接受的情况下,导致数据倾斜的key的个数很少,对于这些数据对于我们的业务本身影响不大的情况下，可以早读取Hive数据的时候,使用where进行过滤,或者使用spark的时候,使用filter进行过滤这样其他的key本身是不会造成数据倾斜的.如果在需要定时的提交作业的情况下,可以使用spark core,进行sample数据的抽样,计算出key的个数，针对key的个数较多的进行一个过滤操作,过滤之后保留的是不造成数据倾斜的key
    实现原理:过滤产生倾斜的key，这样在对于业务影响不大的情况下,只是保留了不造成数据倾斜的key,这样就不会发生数据倾斜的问题了
    优点:实现简单，效果明显，但是比较局限,因为大多数场景下，造成数据倾斜的key可不是1到2个左右
2>提高shuffle的reduce的并行度(主要是在redcued端，某个task的数据量过大，导致运行慢,增加shuffle reduce的并行度,这样就可以使得每个task分配到更少的数据量,而且使造成数据倾斜的key也可以分配到其他的task中去,达到数据倾斜的缓解的作用)
      实现思路:在对于rdd的shuffle的算子的时候,给算子传入一个参数,即是并行度的参数,该并行度的主要思想是shuffle read task的数量,一个是读取速度快,一个是有多少个task，并行度就是几，这样的话,每个task的分担的数据量就少了，缓解数据倾斜,在spark sql中,出现shuffle的hql语句的时候，我们也经常设置这样的值spark.sql.shuffle.partitions，该参数代表了shuffle read rask的并行度,默认值时200,对于一些场景，这个值是太小了
     优点:实现简单,可以有效缓解数据倾斜
     缺点：只是起缓解作用，不能从根本上解决数据倾斜.
3>利用一个随机数,实现局部聚合+全局的聚合
       使用groupbykey,reducebykey的场景下使用
       方案思路:在使用groubykey之前，先进行对于对于key加上一个随机数,这样在使用groupbykey的时候，就会使得导致数据倾斜的key发散到不同的task,随后在讲随机的数取出，再次groupbykey,就会得到最终的结果
                在使用reducebykey之前，先进行对于key加上一个随机数，这样就会使得导致数据倾斜的key,发散到不同的Task，进行reducebykey,随后，进行随机数字的去除,再次进行reducebykey，就会德大最终的结果
       方案的优点:进行聚合类的shuffle操作导致的数据倾斜，效果是很是不错,使得spark作业有大幅度的上升
4>将reduce join转换为map join
       方案适用场景:在对RDD的join操作的时候,或者spark sql 使用join的时候,而且join的时候，其中一个表比较小(比如几百m或者几g)
       方案实现思路:不使用join进行连接操作,而是使用broadcast变量与map类算子实现join,进而规避shuffle类的操作,较小的rdd中的数据进行collect拉去到driver的内存中,然后将其转变为broadcast变量,接着对另一个rdd进行map算子,在算子的函数内,从broadcast变量中获取较小rdd的全量数据，与当前rdd的key进行匹配,如果key相同的话,就进行拼接起来
       方案实现原理:普通的join就会走shuffle操作,而一旦shuffle,就相当于将相同的key通过shuffle read task拉去到同一个节点在去join操作,此时就是reduce join,但是如果一个rdd的数据量比较小的时候,则就可以进行将小的rdd进行collect，转变为广播变量,进行map里面的进行key的匹配，进行拼接，有效的避免了shuffle操作.
     方案缺点，一般使用与大表和小表的join，因为要将小表collect操作，会将数据全部拉去到driver的内存，所以driver要足够的大放的下这些数据,否则有可能发生数据倾斜
5>采样倾斜的key，分拆进行join操，随后进行union操作
       方案适用的场景,2个rdd的数据都是特别的大,进行的join操作,而且导致数据倾斜的key只有少数
       方案实现思路:1>首先计算出导致数据倾斜的key,可以使用sample进行数据的抽样,计算出导致数据倾斜的key,
                    2>将导致数据倾斜的key的rdd分离出来，从而就会有2个rdd的
                    3>分别将这2个rdd与其他的rdd进行join操作
                    4>进行union操作，这样就可以得到最终的结果
      方案缺点:如果导致数据倾斜的key比较多，则不适合这样的场景
6>使用随机的前缀和扩容rdd进行join
       方案适用场景:导致数据倾斜的key有很多个
      方案实现思路:1>选择一个Rdd，使用flatmap，进行扩容,将每一条数据映射为多条数据,每一个映射出来的数据,key都自带了一个随机数
                   2>针对另外一个rdd,做普通的map映射操作,每条数据的key,都打上一个随机数,
                   3>最后2个rdd进行join操作
     方案优点:对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。
     方案缺点:该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。
7>以上结合起来使用，达到最终的效果
      
