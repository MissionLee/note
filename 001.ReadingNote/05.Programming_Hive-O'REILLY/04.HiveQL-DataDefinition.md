# HiveQL: Data Definition

`!!!这部分没有完全看完!!!`

HiveQL is the Hive query language. Like all SQL dialects in widespread use, it doesn’t fully conform to any particular revision of the ANSI SQL standard. It is perhaps closest to MySQL’s dialect, but with significant differences. `Hive offers no support for rowlevel inserts, updates, and deletes.` Hive doesn’t support transactions. Hive adds extensions to provide better performance in the context of Hadoop and to integrate with custom extensions and even external programs.\
`Hive不支持行级操作`

Still, much of HiveQL will be familiar. This chapter and the ones that follow discuss the features of HiveQL using representative examples. In some cases, we will briefly mention details for completeness, then explore them more fully in later chapters. This chapter starts with the so-called data definition language parts of HiveQL, which are used for creating, altering, and dropping databases, tables, views, functions, and indexes. We’ll discuss databases and tables in this chapter, deferring the discussion of views until Chapter 7, indexes until Chapter 8, and functions until Chapter 13. We’ll also discuss the SHOW and DESCRIBE commands for listing and describing items as we go.

Subsequent chapters explore the data manipulation language parts of HiveQL that are used to put data into Hive tables and to extract data to the filesystem, and how to explore and manipulate data with queries, grouping, filtering, joining, etc

## Databases in Hive

The Hive concept of a database is essentially just a catalog or namespace of tables. However, they are very useful for larger clusters with multiple teams and users, as a way of avoiding table name collisions. It’s also common to use databases to organize production tables into logical groups.\
`Hive中的数据库本质上是个目录或命名空间,对于大集群来说,这很重要`

If you don’t specify a database, the default database is used.

The simplest syntax for creating a database is shown in the following example:

```bash
hive> CREATE DATABASE financials;
```

Hive will throw an error if financials already exists. You can suppress these warnings with this variation:

```bash
hive> CREATE DATABASE IF NOT EXISTS financials;
```

While normally you might like to be warned if a database of the same name already exists, the IF NOT EXISTS clause is useful for scripts that should create a database onthe-fly, if necessary, before proceeding.

You can also use the keyword `SCHEMA` instead of `DATABASE` in all the database-related commands.

At any time, you can see the databases that already exist as follows:

```sql
hive> SHOW DATABASES;
default
financials
hive> CREATE DATABASE human_resources;
hive> SHOW DATABASES;
default
financials
human_resources
```

If you have a lot of databases, you can restrict the ones listed using a regular expression, a concept we’ll `explain in “LIKE and RLIKE” on page 96`, if it is new to you. The following example lists only those databases that start with the letter h and end with any other characters (the .* part):

```sql
hive> SHOW DATABASES LIKE 'h.*';
human_resources
hive> ...
```

Hive will create a directory for each database. Tables in that database will be stored in subdirectories of the database directory. The exception is tables in the default database, which doesn’t have its own directory.

The database directory is created under a top-level directory specified by the property `hive.metastore.warehouse.dir`, which we discussed in `“Local Mode Configuration” on page 24` and `“Distributed and Pseudodistributed Mode Configuration” on page 26`. Assuming you are using the default value for this property, `/user/hive/` warehouse, when the financials database is created, Hive will create the directory `/user/ hive/warehouse/financials.db`. Note the `.db` extension.

You can override this default location for the new directory as shown in this example:

```sql
hive> CREATE DATABASE financials
 > LOCATION '/my/preferred/directory';
```

You can add a descriptive comment to the database, which will be shown by the `DESCRIBE DATABASE <database>` command.

```sql
hive> CREATE DATABASE financials
 > COMMENT 'Holds all financial tables';
hive> DESCRIBE DATABASE financials;
financials Holds all financial tables
 hdfs://master-server/user/hive/warehouse/financials.db
```

Note that `DESCRIBE DATABASE` also shows the directory location for the database. In this example, the URI scheme is hdfs. For a MapR installation, it would be maprfs. For an Amazon Elastic MapReduce (EMR) cluster, it would also be hdfs, but you could set hive.metastore.warehouse.dir to use Amazon S3 explicitly (i.e., by specifying s3n:// bucketname/… as the property value). You could use s3 as the scheme, but the newer s3n is preferred.

In the output of `DESCRIBE DATABASE`, we’re showing master-server to indicate the URI authority, in this case a DNS name and optional port number (i.e., server:port) for the “master node” of the filesystem (i.e., where the NameNode service is running for HDFS). If you are running in pseudo-distributed mode, then the master server will be localhost. For local mode, the path will be a local path, `file:///user/hive/warehouse/ financials.db`.\
`DESCRIBE DATABASE输出的URI,master-server在HDFS中应该是NameNode所在服务器`

If the authority is omitted, Hive uses the master-server name and port defined by the property `fs.default.name` in the Hadoop configuration files, found in the `$HADOOP_HOME/conf` directory.\
`如果权限信息省略了,hive会将Hadoop配置文件中的fs.default.name作为master-server所对应的服务器名和端口号`

To be clear, `hdfs:///user/hive/warehouse/financials.db` is equivalent to `hdfs://masterserver/user/hive/warehouse/financials.db`, where master-server is your master node’s DNS name and optional port.

For completeness, when you specify a relative path (e.g., some/relative/path), Hive will put this under your home directory in the distributed filesystem (e.g., hdfs:///user/<username>) for HDFS. However, if you are running in local mode, your current working directory is used as the parent of some/relative/path.\
`为了保持完整性,当用户指定要给相对路径,对于HDFS和Hive,都会将这个路径放到HDFS的指定根目录下,例如hdfs:///user/<username>.如果是本地模式,那么当前的本地工作目录将会是相对路径的父目录`

For script portability, it’s typical to omit the authority, only specifying it when referring to another distributed filesystem instance (including S3 buckets).

Lastly, you can associate key-value properties with the database, although their only function currently is to provide a way of adding information to the output of `DESCRIBE DATABASE EXTENDED <database>`:

```sql
hive> CREATE DATABASE financials
 > WITH DBPROPERTIES ('creator' = 'Mark Moneybags', 'date' = '2012-01-02');
hive> DESCRIBE DATABASE financials;
financials hdfs://master-server/user/hive/warehouse/financials.db
hive> DESCRIBE DATABASE EXTENDED financials;
financials hdfs://master-server/user/hive/warehouse/financials.db
{date=2012-01-02, creator=Mark Moneybags);
```

The USE command sets a database as your working database, analogous to changing working directories in a filesystem:

```sql
hive> USE financials;
```

Now, commands such as SHOW TABLES; will list the tables in this database. Unfortunately, there is no command to show you which database is your current working database! Fortunately, it’s always safe to repeat the USE … command; there is no concept in Hive of nesting of databases.

Recall that we pointed out a useful trick in “Variables and Properties” on page 31 for setting a property to print the current database as part of the prompt (Hive v0.8.0 and later):

```sql
hive> set hive.cli.print.current.db=true;
hive (financials)> USE default;
hive (default)> set hive.cli.print.current.db=false;
hive> ...
```

Finally, you can drop a database:

```sql
hive> DROP DATABASE IF EXISTS financials;
```

The IF EXISTS is optional and suppresses warnings if financials doesn’t exist. By default, Hive won’t permit you to drop a database if it contains tables. You can either drop the tables first or append the `CASCADE` keyword to the command, which will cause the Hive to drop the tables in the database first:

```sql
hive> DROP DATABASE IF EXISTS financials CASCADE;
```

Using the RESTRICT keyword instead of CASCADE is equivalent to the default behavior, where existing tables must be dropped before dropping the database. When a database is dropped, its directory is also deleted.

## Alter Database

You can set key-value pairs in the DBPROPERTIES associated with a database using the
ALTER DATABASE command. No other metadata about the database can be changed,
including its name and directory location:
hive> ALTER DATABASE financials SET DBPROPERTIES ('edited-by' = 'Joe Dba');
There is no way to delete or “unset” a DBPROPERTY.

##　Creating Tables

The CREATE TABLE statement follows SQL conventions, but Hive’s version offers significant　extensions to support a wide range of flexibility where the data files for tables　are stored, the formats used, etc. We discussed many of these options in “Text File　Encoding of Data Values” on page 45 and we’ll return to more advanced options later　in Chapter 15. In this section, we describe the other options available for the CREATE　TABLE statement, adapting the employees table declaration we used previously in “Collection　Data Types” on page 43:

```sql
CREATE TABLE IF NOT EXISTS mydb.employees (
 name STRING COMMENT 'Employee name',
 salary FLOAT COMMENT 'Employee salary',
 subordinates ARRAY<STRING> COMMENT 'Names of subordinates',
 deductions MAP<STRING, FLOAT>
 COMMENT 'Keys are deductions names, values are percentages',
 address STRUCT<street:STRING, city:STRING, state:STRING, zip:INT>
 COMMENT 'Home address')
COMMENT 'Description of the table'
TBLPROPERTIES ('creator'='me', 'created_at'='2012-01-02 10:00:00', ...)
LOCATION '/user/hive/warehouse/mydb.db/employees';
```

First, note that you can prefix a database name, mydb in this case, if you’re not currently working in the target database.\
`可以带上库名作为表明的前缀`

If you add the option IF NOT EXISTS, Hive will silently ignore the statement if the table already exists. This is useful in scripts that should create a table the first time they run. However, the clause has a gotcha you should know. If the schema specified differs from the schema in the table that already exists, Hive won’t warn you. If your intention is for this table to have the new schema, you’ll have to drop the old table, losing your data, and then re-create it. Consider if you should use one or more ALTER TABLE statements to change the existing table schema instead. See “Alter Table” on page 66 for details.

```note
If you use IF NOT EXISTS and the existing table has a different schema
than the schema in the CREATE TABLE statement, Hive will ignore the
discrepancy.
```

You can add a comment to any column, after the type. Like databases, you can attach a comment to the table itself and you can define one or more table properties. In most cases, the primary benefit of TBLPROPERTIES is to add additional documentation in a key-value format. However, when we examine Hive’s integration with databases such as DynamoDB (see “DynamoDB” on page 225), we’ll see that the TBLPROPERTIES can be used to express essential metadata about the database connection.

Hive automatically adds two table properties: `last_modified_by` holds the username of the last user to modify the table, and `last_modified_time` holds the epoch time in seconds of that modification.\
`hive自动添加两个属性,记录最后修改人和修改时间`

```note
A planned enhancement for Hive v0.10.0 is to add a SHOW TBLPROPERTIES
table_name command that will list just the TBLPROPERTIES for a table.
```

Finally, you can optionally specify a location for the table data (as opposed to metadata, which the metastore will always hold). In this example, we are showing the default location that Hive would use, `/user/hive/warehouse/mydb.db/employees`, where /user/ hive/warehouse is the default “warehouse” location (as discussed previously), mydb.db is the database directory, and employees is the table directory.\
`关于指定表路径,建议使用默认路径,自己在测试的时候发现,如果指定路径,制定的路径会同上一层的路径重复,产生一些奇妙的影响,也就是创建了一个库,指定了路径,而在hive中这个路径映射到了指定路径的上一层,也就是default库里面,在创建库中创建的表,也会出现在defualt库里面`

By default, Hive always creates the table’s directory under the directory for the enclosing database. The exception is the default database. It doesn’t have a directory under /user/hive/warehouse, so a table in the default database will have its directory created directly in /user/hive/warehouse (unless explicitly overridden).

```note
To avoid potential confusion, it’s usually better to use an external table
if you don’t want to use the default location table. See “External
Tables” on page 56 for details.为了避免混淆,如果用户不想使用默认的表路径,那么最好使用外部表!!!! 这个很重要
```

You can also copy the schema (but not the data) of an existing table:\
`用户还可以拷贝一张已经存在的表的模式=>这种情况下,除了LOCATION,其他信息都不能覆盖定义了`

```sql
CREATE TABLE IF NOT EXISTS mydb.employees2
LIKE mydb.employees;
```

This version also accepts the optional LOCATION clause, but note that no other properties, including the schema, can be defined; they are determined from the original table. The SHOW TABLES command lists the tables. With no additional arguments, it shows the tables in the current working database. Let’s assume we have already created a few other tables, table1 and table2, and we did so in the mydb database:

```sql
hive> USE mydb;
hive> SHOW TABLES;
employees
table1
table2
```

If we aren’t in the same database, we can still list the tables in that database:

```sql
hive> USE default;
hive> SHOW TABLES IN mydb;
employees
table1
table2
```

If we have a lot of tables, we can limit the ones listed using a regular expression, a concept we’ll discuss in detail in “LIKE and RLIKE” on page 96:

```sql
hive> USE mydb;
hive> SHOW TABLES 'empl.*';
employees
```

Not all regular expression features are supported. If you know regular expressions, it’s better to test a candidate regular expression to make sure it actually works!

The regular expression in the single quote looks for all tables with names starting with empl and ending with any other characters (the .* part).

```note
Using the IN database_name clause and a regular expression for the table
names together is not supported.
```

We can also use the DESCRIBE EXTENDED mydb.employees command to show details about the table. (We can drop the mydb. prefix if we’re currently using the mydb database.) We have reformatted the output for easier reading and we have suppressed many details to focus on the items that interest us now:

```sql
hive> DESCRIBE EXTENDED mydb.employees;
name string Employee name
salary float Employee salary
subordinates array<string> Names of subordinates
deductions map<string,float> Keys are deductions names, values are percentages
address struct<street:string,city:string,state:string,zip:int> Home address
Detailed Table Information Table(tableName:employees, dbName:mydb, owner:me,
...
location:hdfs://master-server/user/hive/warehouse/mydb.db/employees,
parameters:{creator=me, created_at='2012-01-02 10:00:00',
 last_modified_user=me, last_modified_time=1337544510,
 comment:Description of the table, ...}, ...)
```

Replacing `EXTENDED` with `FORMATTED` provides more readable but also more verbose output.

The first section shows the output of DESCRIBE without EXTENDED or FORMATTED (i.e., the schema including the comments for each column).

If you only want to see the schema for a particular column, append the column to the table name. Here, EXTENDED adds no additional output:

```sql
hive> DESCRIBE mydb.employees.salary;
salary float Employee salary
```

Returning to the extended output, note the line in the description that starts with location:. It shows the full URI path in HDFS to the directory where Hive will keep all the data for this table, as we discussed above.


```note
We said that the last_modified_by and last_modified_time table properties
are automatically created. However, they are only shown in the
Detailed Table Information if a user-specified table property has also
been defined!
```

## Managed Tables \ 管理表 => 普通的表,也叫内部表,hive可以掌控整个表和其中数据

The tables we have created so far are called managed tables or sometimes called internal
tables, because Hive controls the lifecycle of their data (more or less). As we’ve seen,
Hive stores the data for these tables in a subdirectory under the directory defined by
hive.metastore.warehouse.dir (e.g., /user/hive/warehouse), by default.
When we drop a managed table (see “Dropping Tables” on page 66), Hive deletes
the data in the table.
However, managed tables are less convenient for sharing with other tools. For example,
suppose we have data that is created and used primarily by Pig or other tools, but we
want to run some queries against it, but not give Hive ownership of the data. We can
define an external table that points to that data, but doesn’t take ownership of it.

## External Tables \ 外部表

Suppose we are analyzing data from the stock markets. Periodically, we ingest the data for NASDAQ and the NYSE from a source like Infochimps (http://infochimps.com/da tasets) and we want to study this data with many tools. (See the data sets named infochimps_dataset_4777_download_16185 and infochimps_dataset_4778_download_ 16677, respectively, which are actually sourced from Yahoo! Finance.) The schema we’ll use next matches the schemas of both these data sources. Let’s assume the data files are in the distributed filesystem directory /data/stocks.

The following table declaration creates an external table that can read all the data files for this comma-delimited data in /data/stocks:

```sql
CREATE EXTERNAL TABLE IF NOT EXISTS stocks (
 exchange STRING,
 symbol STRING,
 ymd STRING,
 price_open FLOAT,
 price_high FLOAT,
 price_low FLOAT,
 price_close FLOAT,
 volume INT,
 price_adj_close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/data/stocks';
```

The EXTERNAL keyword tells Hive this table is external and the LOCATION … clause is
required to tell Hive where it’s located.
Because it’s external, Hive does not assume it owns the data. Therefore, dropping the
table does not delete the data, although the metadata for the table will be deleted.
There are a few other small differences between managed and external tables, where
some HiveQL constructs are not permitted for external tables. We’ll discuss those when
we come to them.
However, it’s important to note that the differences between managed and external
tables are smaller than they appear at first. Even for managed tables, you know where
they are located, so you can use other tools, hadoop dfs commands, etc., to modify and
even delete the files in the directories for managed tables. Hive may technically own
these directories and files, but it doesn’t have full control over them! Recall, in “Schema
on Read” on page 48, we said that Hive really has no control over the integrity of the
files used for storage and whether or not their contents are consistent with the table
schema. Even managed tables don’t give us this control.
Still, a general principle of good software design is to express intent. If the data is shared
between tools, then creating an external table makes this ownership explicit.
You can tell whether or not a table is managed or external using the output of DESCRIBE
EXTENDED tablename. Near the end of the Detailed Table Information output, you will
see the following for managed tables:
... tableType:MANAGED_TABLE)
For external tables, you will see the following:
... tableType:EXTERNAL_TABLE)
As for managed tables, you can also copy the schema (but not the data) of an existing
table:
CREATE EXTERNAL TABLE IF NOT EXISTS mydb.employees3
LIKE mydb.employees
LOCATION '/path/to/data';
If you omit the EXTERNAL keyword and the original table is external, the
new table will also be external. If you omit EXTERNAL and the original
table is managed, the new table will also be managed. However, if you
include the EXTERNAL keyword and the original table is managed, the new
table will be external. Even in this scenario, the LOCATION clause will
still be optional.