# `

/home/missingli/BigDataLi/002.基础学习/05.SparkBasic/Spark-RDD源码分析与算子测试/算子测试/Transformations/03.filter.md
```scala
  /**
   * Return a new RDD containing only the elements that satisfy a predicate.
   */
  def filter(f: T => Boolean): RDD[T] = withScope {
    val cleanF = sc.clean(f)
    new MapPartitionsRDD[T, T](
      this,
      (context, pid, iter) => iter.filter(cleanF),
      preservesPartitioning = true)
  }
```

类似与之前的flatMap，最终做运算的是Iterator底层的方法


[Scala Iterator filter](../../../../06.ScalaBasic/ScalaCollection/Iterator/ScalaIterator-filter.md)

- 说明
  - 对rdd的每个元素进行筛选，符合条件的保留
  - 接受一个返回 布尔值 的函数作为参数
  - 返回 true保留，false

- 测试

```scala
package basic

import org.apache.spark.sql.SparkSession

/**
  * @author: MissingLi
  * @date: 02/04/18 16:52
  * @Description:
  * @Modified by:
  */
object TestFilter {
  val ss = SparkSession.builder().master("local").appName("1").getOrCreate()
  val sc = ss.sparkContext
  val rdd = sc.textFile("/home/missingli/IdeaProjects/SparkLearn/src/main/resources/sparkbasic.txt")
  sc.setLogLevel("error")

  def main(args: Array[String]): Unit = {
    rdd.foreach(println)

    println("------------------")
    rdd.map(line=>line.split(",",-1)).filter(r=>1==(r(0).toInt%2)).map(_.mkString("_")).foreach(println)
    // 1. 用 ， 分隔开 每行
    // 2. 筛选第一个数字未奇数的行
    // 3. 拼成字符串
    // 4. 打印

    // 锻炼以下 scala的使用 
    def oddFilter[T](strA : Array[T]):Boolean={
      val num = strA(0).toString.toInt
      return 1==num%2
    }
    rdd.map(line=>line.split(",",-1)).filter(oddFilter).map(_.mkString("_")).foreach(println)

  }

}
```
打印结果
```note
1,a,c,b
2,w,gd,h
3,h,r,x
4,6,s,b
5,h,d,o
6,q,w,e
------------------
1_a_c_b
3_h_r_x
5_h_d_o
```

- 以上，符合预期