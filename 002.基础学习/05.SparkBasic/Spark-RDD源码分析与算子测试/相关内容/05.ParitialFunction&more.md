# 偏函数

可以学到的内容
- 偏函数
- case 与偏函数
- new 一个trait！！！

参考文章 https://blog.csdn.net/bluishglc/article/details/50995939 原文禁转，这里贴个连接

## 起因

再学习 spark部分的源码的时候，看到 collect()方法有一种重载，可以接受一个函数作为参数，注释上写到这个函数用于筛选符合函数规定条件的RDD元素，本一为和filter的功能基本相同，细看之后发现了这里传入的参数函数要求是一个

PartialFunction

由此学习了这部分相关源码，并再往上搜索了前人的一些经验

## 首先做一个具体实现，然后再分析其中原理

```scala
// 一个自定义的 PartialFunction 的实现类
// 我在这里 隐入了 Serializable是因为需要在spark中使用，没有相关需求则不需要隐入
class MyParitialFunction extends Serializable   with PartialFunction [Any,String]{
    // 用来判断 入参 是否符合条件
    // 用源码中的说法： Checks if a value is contained in the function's domain.
    //                检测输入是否在函数的领域（符合入参要求）内
  override def isDefinedAt(x: Any): Boolean = if(x.toString.startsWith("A")) true else false
    // 这个apply是 trait Function1 里面的， 可以用  val x = new Function1 然后点进去看一下源码
  override def apply(v1: Any): String = v1.toString
}


object TestCollect {
  val ss = SparkSession.builder().master("local").appName("basic").getOrCreate()
  val sc = ss.sparkContext
  sc.setLogLevel("error")
  val a1 = sc.textFile("/home/missingli/IdeaProjects/SparkLearn/src/main/resources/sparkzip1.txt")
  val a2 = sc.textFile("/home/missingli/IdeaProjects/SparkLearn/src/main/resources/sparkzip2.txt")
  val b1 = sc.textFile("/home/missingli/IdeaProjects/SparkLearn/src/main/resources/sparkzip3.txt")
  val b2 = sc.textFile("/home/missingli/IdeaProjects/SparkLearn/src/main/resources/sparkzip4.txt")

  def main(args: Array[String]): Unit = {
    val rdd = a1 ++ a2 ++ b1 ++ b2 //不要害怕 我的四份测试数据内容实际上是 A1～A6 ，B1～B6 ，因为偷懒直接用的其他测试的数据
    val array = rdd.collect()
    for (str <- array) {
      println(str)
    }
//    val x = List(1, 2, 3, "abc")
//    val y = x.collect {
//      case i: Int  => i
//      case i: String => "find a string"
//    }
//    for (i <- y) {
//      println(i)
//    }

        //对于 List来说，collect中给一个偏函数，最大的作用就是提取List中指定类型的内容，不过我既然能够灵活使用，我就所变做了一点小业务
    // PartialFunction with List
    val x = List("A1","A2","A3","B4",5,6,7)
    val f = new PartialFunction[String, String] {
      override def isDefinedAt(x: String): Boolean = if (x.startsWith("A")) true else false

      override def apply(v1: String): String = v1 + ";"
    }
    val f2 = new PartialFunction[Any, String] {
      // in fact we use isDefinedAt with :  isInstanceOf[...]
      override def isDefinedAt(x: Any): Boolean = if (x.toString.startsWith("A")) true else false

      override def apply(v1: Any): String = v1.toString
    }
//    val x2 = x.collect(f)    can note resolve reference with such signature
//                             看List的源码，指定了 PartialFunction的类参数类型
    println("----------x3--------------")
    val x3 = x.collect(f2)
    for(str <-x3){
      println(str)
    }


    val array2 = rdd.collect { case a: String => {
      if (a.startsWith("A")) a
    }
    }
    val array3 = rdd.collect(new MyParitialFunction)


    println(" array2")
    for (str <- array2) {
      println(str)
    }
    println("array 3")
    for (str <- array3) {
      println(str)
    }
  }
}
```

输出结果

```note
A1
A2
A3
A4
A5
A6
B1
B2
B3
B4
B5
B6
----------x3--------------
A1
A2
A3
 array2
A1
A2
A3
A4
A5
A6
()
()
()
()
()
()
array 3
A1
A2
A3
A4
A5
A6
```

- 效果
  - List的collect 对传入的PartialFunctrion要求更高，指定了第一个类参数（函数也是类）为 Any
  - 在Spark RDD相关的Collect中用了两种方式给定偏函数
    - 1.使用case方法
      - 最上面附加的连接里面有讲相关内容，case 与 PartialFunction的相关实现，我在这里根据我的测试做一下总结
        - 

        ```scala
        val array2 = rdd.collect { case a: String => {
            if (a.startsWith("A")) a
        }
        ```
        - a:String 相当于在PartialFunction中实现 isDefinedAt
        - case的方法体，相当于 apply 方法
        - 在被注释调的部分
        ```scala
        val x = List(1, 2, 3, "abc")
        val y = x.collect {
          case i: Int  => i
          case i: String => "find a string"
        }
        for (i <- y) {
          println(i)
        }
        ```
        - 这里可以和预期的一样，实现类似 match case（scala） /switch case（java）
    - 2.创建一个类继承 PartialFunction，并在其中写自己的实现
      - 由于spark的分布式需求，传给collect的方法（传给所有算子的方法），需要是可序列化的，所以在自定的时候加上了这一点
      - 使用case 函数 也能通过运行，说明 case 解析后的函数 是可以序列化的，这些在编译中实现（？）
- 关于 new 一个trait 的思考
  -  类似与Java中的接口
    - 在Java中，我们可以父类引用指向子类对象，以接口类型创建一个子类的实例
  - 我想 在scala中 new 一个trait也是同样的道理
    - 在new trait的时候，要求重写trait中的方法
    - 实际上相当于创建了一个匿名的 trait实现，并将其赋给一个变量