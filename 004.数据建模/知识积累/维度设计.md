# 维度设计

## 基础

- 度量称为`实时`,环境成为`维度`,维度是用于分析实时所需的多样环境
- 维度所包含的表示为度的列称为`维度属性`=>`用于约束,汇总,分类,排序`
- 维度属性[`维度列`],是查询约束条件,分组和报表标签生成的基本来源,是数据易用性的关键
- OLAP 联机分析处理系统
- OLTP 联机事务处理系统

### 维度的基本设计方法

- 一.选择维度
- 二.确定主维表.一般是ods表
- 三.确定相关维表.哪些表和主维表有关联性
- 四.确定维度属性
  - 1.从主维表中选择维度属性或生成新的维度属性
  - 2.从相关维表中选择维度属性或生成新的维度属性.

- 1.保证维度的一致性
- 2.确定主维度=>例如`商品表`,`用户表`
- 3.确定相关维度=>例如`商品类型`,`卖家买家`
- 4.确定唯独属性
  - 尽可能生成丰富的维度属性`几十几百个`
  - 尽可能多的给出有意义的文字描述=>`属性不应该是编码,而应该是真正的文字`,例如给出一个ID就给出相应的name,id用于关联,name用于标签
  - 区分数值型属性和事实=>`主要看字段的作用,用于查询比较的一般是维度属性,用于参与度量的计算则作为实时,有些字段可以兼有这两种作用`
  - 尽量沉淀出通用的维度属性=>`有些重要属性可能隐藏在某个字段[字段编码等]之中,可以根据情况单独提取出来`
- 维度是有层次结构的,在属性的层次结构中进行钻取是数据钻取的方法之一.`属性层次`=>实例化为`一系列维度`

    属性层次被实例化为多个维度[雪花模式]? 还是 作为维度的属性存在于商品维度中?
    实例化为多个维度=>事务处理系统OLTP的底层数据结构在设计商采用这种规范化技术=>将重复属性转移至自身所属表中,删除冗余数据=>例如:商品中记录[类目ID,品牌ID等],而[类目,品牌]等实例化为一个表(这种模式很方便服务于事务处理系统,但是如果需要分析,那么需要进行一些关联操作,把这些ID关联成对应的名字,才能够让分析人员使用)
    反范式化就是把分散在各个表中的维度属性直接存储下来,用存储空间换取计算难度.

- [雪花模式]规范化:表中存维度ID;反规范化:表中存具体内容
- 一致性维度和交叉探查
  - 共享维度表
  - 一致性上卷,一个维度中的属性是另一个维度的属性的子集,且两个维度的公共维度属性结构和内容相同
  - 交叉属性,两个维度有部分相同的唯独属性,如`商品属于某类目`,`某店铺的主营内容也属于某类目`

## 维度设计高级主题

### 维度整合

- 数据仓库:面向主题的,集成的,非易失的随时间变化的数据集合=>用于支持管理人员决策
- 应用之间差异
  - 编码,命名习惯,度量单位
  - 物理实现

    数据从面向应用的操作环境(网站后台,app后台等)进入数据仓库后,需要进行数据集成,`将各种意义相同形式不同的数据统一起来`

- 数据仓库使这些统一
  - 命名规范
  - 字段类型
  - 公共代码及代码值
  - 业务含义相同的表统一
    - 主从结构表:将多个表都有的相同字段放在主表中,从属信息分别放置`可以采用复合主键或者唯一主键`
    - 直接合并`谨慎选择`
    - 不合并
- 维度表的整合和上面几方面相同
- 表级别整合
  - 垂直整合:`不同来源的表包含相同的数据集,只是存储的信息不同`,例如:会员基础信息,扩展信息,等级信息等表=>整合
  - 水平整合:`不同来源,不同数据及,不同子集间也无交叉`=>在阿里,通常采用将来源表各个子集的自然键作为联合主键的方式,并且在物理实现时将来源字段作为`分区字段`

    维度通常可以按照类别或类型进行细分(比如,商品都有价格,标题,类型,某些商品还有独有的属性,比如重量),所以就涉及到`表拆分`的问题,一种是将维度的不同分类实例化为不同的维度,同时在主维度中保存公共属性;一种是维护单一维度,包含所有的肯能性.两种方案都不能保证在所有情况下都最优化.

- 水平差分
  - 考虑三个原则:扩展性,效能,易用性
  - 两个依据
    - 维度不同分类的属性差异情况
    - 业务关联程度

    维度的丰富程度,,决定了数据仓库的分析潜能,同时又使用反范式化.把很多字段放在同一个表中,这些字段中的某些维度属性`热度高`,有些`热度滴`,[热度是指使用频繁之类的]

- 垂直拆分
  - 处于扩展性,产出时间,易用性等方面考虑,设计主从维度.主维度表存放稳定,产出时间早,高热度的属性
- 历史归档

## 维度变化

    数据仓库的重要特点之一是反映历史变化

  有时候维度相关的内容需要改变,比如某个商品原来属于某个维度的A属性,后来要调整为B.这种变化相对于数据的增加很慢,所以叫做缓慢变化维,处理方法有几种,选择何种主要看对于历史查询的要求.

- 缓慢变化维
  - 重写维度值
  - 插入新的维度行
  - 添加维度列

  数据仓库的计算周期可能是每天一次,基于这个周期,处理维度变化的方式就是每天保留一份全量快照数据,比如商品唯独,每天保留一份全量商品快照数据

- 快照维度表[`大量消耗存储`]
  - 每天保留一份全量快照

    =>解决方法:极限存储
    先介绍一下历史拉链存储:通过新增两个时间戳字典,将所有以天威粒度的变更数据都记录下来(通常分区字段也是时间戳字段).
    历史拉链存在的问题
    1.前端人员,分析师等不理解这种模型
    2.用start_dt,end_dt做份去,随着时间推移,分区数量会极度膨胀
    => 使用极限存储模式

- 极限存储[`取代历史拉链和时间分区`]
  - 透明化`底层数据还是历史拉链,上层做一个试图操作或者在Hive里面做一个hook,通过分析语法书,把对极限存储钱的表的查询转换成对极限存储表的查询`
  - 分月做历史拉链表
- 微型维度`不方便实际使用`
  - 将一部分不稳定的属性从主维度中一处,并将他们放置到拥有自己代理键的新表中来实现

## 特殊维度

- 递归层次

    `扁平化处理`

  - 层次结构扁平化`如果我们想要统计一个在递归层级较高的维度,可能需要向下递归查询很多级别`
    降低递归层次使用复杂度的最简单和有效的方法是层次结构扁平化,通过建立维度的固定数量级别的属性来实现=>把过低的递归层级摊平(取消),归属到上一级中
  - 存在问题
    - 在这种方案中进行数据分析操作之前,需要知道目标属性,在哪一个层级
    - 叶子目录可能缺少某些级别目录,例:某二级目录的叶子节点,三级目录做分析就统计不到,只能去二级.
      - 可用的一种处理方法是,低级目录如果不存在,就用上级目录向下虚拟,就是三级,四级目录的位置,直接填写二级目录的内容
    - 扁平化仅能

    `层次桥接表处理`
  - 比较扁平化,可以解决存在的问题,但是复制,使用成本高=>`单独维护一个事实表和类目表之间的类目桥接表`
- 行为为度[`事实衍生为度`],例如交易,物流

    按照加工方式,行为维度可以分为以下几种

  - 另一个维度的过去行为:买家最近一次访问的时间
  - 快照事实行为为度:本年消费总额
  - 分组事实行为维度:消费总额分级
  - 复杂逻辑事实行为维度

      对于行为维度,有两种处理方式
      - 将其冗余至现有的维表中:比如加个信用等级字段
      - 加工成单独的维表
  - 参考原则
    - 避免唯独过快增长
    - 避免耦合度过高
  - 多值维度:事实表中的一条记录,在某维表中有多交记录与之对应
    - 针对多至维度,有三种处理方法
      - 降低事实表粒度[基本不可行]
      - 采用多字段
      - 次啊用较为通用的桥接表
  - 多值属性:
    - 三种方式
      - 保持维度主键不变,将多值属性放在维度的一个属性字段中,用键值对表示
      - 保持维度主键不变,将多值属性放在多个字段中,但是需要预留字段,且扩展性不好
      - 维度主键发生变化,一个维度存放多条记录
        - 比如商品sku维表,对于每个商品,有多少sku,就有多少记录,铸剑师商品ID和SKU的ID:`扩展性好,使用方便,但是数据量大`
  - 杂项维度
    - 一些诸如交易类型,支付状态这些维度,放在事实表中导致事实表占用空间过大,单独建立维表,维表又很多,弄一个专门的杂项维度,放这些东西,然后把代理键放在主维表中
    - 一般在逻辑建模中,使用实体的主键作为杂项维度的主键,

## 极限存储主题逻辑方案

    一个思路[`并不完善`]

- 1.通过主键关联,对比昨天全量和今天全量的数据差异,并将这些数据区分为 活跃(Lived)或过期(Expired)数据.
- 2.对于对比的结果数据进行统计,获得每个生命周期下实际的数据条数,统计结果,用来产生不同生命周期的记录到文件目录的映射.
- 3.使用mapreduce数据对第一步结果进行分发,相同生命周期的数据会被写入到对应的唯一的生命周期目录下(依赖第二步的统计结果)
- 4.使用hive双重分区映射生命周期目录,这样用户可以通过灵活的hive分区过滤来获得期望的数据.
- 5.数据验证,为了保证应用极限存储后的结果的正确性,因此增加了数据条数对比的验证规则.

    这种方案遇到的问题
- 产生的目录/文件非常多
  - 产生目录数及文件数按日呈级数增长
  - 一个月产生465个目录,一年66795个[文件数=目录数*reduce数]
  - 对NameNode压力非常大
  - Hive元数据库压力也很大
- 文件大小不均
- 如何快速访问任意一天/一段时间的快照数据
- 不同月份数据并行运行数据丢失问题
- 单个数据标签内数据损坏/丢失导致一段时间内快照不准
- 其他的一些保护机制

## 极限存储的使用方法

- Hive
  - 取某天快照[`原本扫描一个很大的表,来找到某一天的数据,现在找的是首先pt_end大于这个日期,排除了已经死去的部分,pt_start<=这个日期排除了还没产生的一部分,剩下就可以锁定这一天所有(Lived)数据所处的分区了`]
  `select * from tb_name where pt_start <='日期' and pt_end >'日期'`
  - 取某天快照
  `select * from tb_name where exst_pt(pt_start,pt_end,'日期')`
  - 取一段时间快照
  `类似取某天`
- Hadoop
  `List<String>dateLists=DateListGeneratorgenerateExStoreListDirs("/..../tb_name","日期")`
- 等等使用

## 性能优化

set io.sort.spill.percent=0.80
set io.sort.mb=512
set io.sort.factor=32
set io.sort.record.percent=0.04
set maperd.reduce.parallel.copies=8
set maperd.job.shuffle.input.buffer.percent=0.70

## 易用性优化

- Hive层增加hook,实现SQL自动替换,对用户及上层业务透明